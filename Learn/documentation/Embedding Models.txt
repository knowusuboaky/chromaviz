
Leaderboard:
===============================================
https://huggingface.co/spaces/mteb/leaderboard
===============================================

Known Compatible Models (not neccessarily all, others may or may not work)



Name								para	MemGB	dim	tokens	Avg	Class	Clust	Pairs
-----								-----	-----	---	-------	---	----	-----	-----
bge-micro-v2						17	0.06	384	512		56.57	68.04	39.18	82.81		Y	https://huggingface.co/TaylorAI/bge-micro-v2
gte-micro-v4						19	0.07	384	512			68.13	39.54	82.59		Y	https://huggingface.co/Mihaiii/gte-micro-v4
all-MiniLM-L6-v2						23	0.09	384	512		56.09	62.62	41.94	82.37		Y	Default
GIST-all-MiniLM-L6-v2					23	0.08	384	512		59	72.72	39.48	83.39		Y	https://huggingface.co/avsolatorio/GIST-all-MiniLM-L6-v2
all-MiniLM-L12-v2						33	0.12	384	512		56.53	63.21	41.81	82.46		Y	https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2
GIST-small-Embedding-v0					33	0.12	384	512		62.72	76.11	44.82	84.68		Y	https://huggingface.co/avsolatorio/GIST-small-Embedding-v0		
bge-small-en-v1.5						33	0.12	384	512		62.17	74.14	43.82	84.92		Y	https://huggingface.co/BAAI/bge-small-en-v1.5
stella-base-en-v2						55	0.2	768	512		62.61	75.28	44.9	86.45		Y	https://huggingface.co/infgrad/stella-base-en-v2
all-mpnet-base-v2						110	0.41	768	512		57.77	65.03	43.69	83.04		Y	https://huggingface.co/sentence-transformers/all-mpnet-base-v2
gte-large							335	1.25	1024	512		63.13	73.33	46.84	85		Y	https://huggingface.co/thenlper/gte-large
KaLM-embedding-multilingual-mini-instruct-v1	494	1.84	896	131072	64.74	85.1	45.46	83.92		Y	https://huggingface.co/HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1
stella_en_1.5B_v5						1543	5.75	8192	131072	71.19	87.63	57.69	88.07		Y	https://huggingface.co/dunzhang/stella_en_1.5B_v5


Recommended							para	MemGB	dim	tokens	Avg	Class	Clust	Pairs
------------						-----	-----	---	-------	---	----	-----	-----
GIST-all-MiniLM-L6-v2					23	0.08	384	512		59	72.72	39.48	83.39		super fast, faster than default all-MiniLM-L6-v2, and better 75% of metrics
GIST-small-Embedding-v0					33	0.12	384	512		62.72	76.11	44.82	84.68		as fast as default all-MiniLM-L6-v2 AND significantly better in ALL metrics
stella-base-en-v2						55	0.2	768	512		62.61	75.28	44.9	86.45		still fast, and although it seems youd be better off using GIST-small-Embedding-v0, this has higher dimensionality
KaLM-embedding-multilingual-mini-instruct-v1	494	1.84	896	131072	64.74	85.1	45.46	83.92		if large context and higher accuracy classification is needed and resources can handle. 
	
